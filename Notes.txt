# One-hot vs integer encoding of tile values
    Powers of two naturally suggest a binary representation. The powers of two represented as a bit sequence correspond to one-hot encoding. While tile values are not continuous, numerican comparison is important for the logic of the game. Representing the value as the exponent allows comparison and addition operations (for both the game logic and the neural network).
    I will use integer encoding (i.e x=2^n).


# move function implementation
    The merge_row function merges and tightens a single row to the left side. I have two ways to perform moves in non-left directions: 1) to transform, using transpose and flip, the matrix such that the desired direction points left, or 2) to change slicing operations such that input row to merge_row is oriented in the desired direction. Method 2) was previously names alt/alternative. I performed timing comparisons:
    
    print(timeit.timeit('a.board=np.zeros((4,4))\nfor _ in range(8):\n    a.generate_tile()\na.move_up()',
          setup='from __main__ import a,np',number=10000))
    move_left   => 1.867    
    move_up     => 1.970, 2.037
    move_up_alt => 2.033, 2.025
    move_right  => 1.994, 2.109
    move_right_alt 2.092, 1.994
    move_down   => 2.044, 2.034
    move_down_alt  1.982, 1.960
    Alterative is marginally faster by about 0.8%
    I will use the slicing method and update function names.


# Merge implementation
    Current move implementation performs the operation row by row using a merge_row function. I wondered whether this could be done via a single operation on the whole matrix, which uses np.where to get the coordinates of all nonzero tiles and then iterates through them to generate the new matrix. However, the generation process still works like a row-by-row system because it keep tracks on the current row to perform its calculations. I performed timing comparisons:
    
    move_left         => 1.886  1.894, 1.851
    move_left_matrix  => 2.041, 2.012, 1.966
    matrix implementation is slower by about 6.9%
    I will keep current implementation. Matrix implementation goes to unused code.


# How to reset back to starting state without copying object
    1. Save current board and score
    2. Trace a line
    3. Record score (and board)
    4. Set board and score back to starting state


# Monte Carlo tree search implementation
    Initial version requires no input from neural networks. Each of the four moves are explored equally with a number of lines. The original state is saved, and multiple lines are generated using a move-selection method until the game-over state is reached. Final scores are combined using mean to give the expected value estimate for final score for each move. Alternatives to explore include median, mode, and variance. 
    Using this MCTS method to choose moves (implemented in play_MCTS) is significantly superior to using the fixed move order (L,U,R,D) method. Note that the MCTS does use the fixed method to generate lines. Representative results:
    
    play_fixed:
        Score: 3380, 2636, 2628, 1480, 1152 (4000s also observed)
        Max tile: 128 or 256
    
    play_MCTS (number = 5):
        Score: 6300, 11536, 10520
        Max tile: 1024
    play_MCTS (number = 10):
        Score: 15520 
        Max tile: 1024 also with 512, 256, and two 64 tiles

    Note 1: This method is not truly a 'tree search' because it does not need to remember intermediate states between the starting and final states. It does not use information about previous searches for generating new lines. Each line is able to be unique because of the probabilistic nature of new tile value and placement.

    Note 2: A more intelligent generating method (rather than fixed move order), such as with a neural network, will significantly improve the relevance of each line to the true value of each starting move. This will increase the accuracy of of the search as well as decrease the number of lines needed for a meaningful result.


# Future MCTS implementation involving neural network
    The following changes should be considered:
    - Multi-armed bandit for exploring the four moves. If the NN prefers one move over the others, that move can be explored more. However, in this setting, it may actually be detrimental. There is no benefit to exploring the same line more besides the numerical law of large numbers because the MCTS implementation does not use previous search knowledege. Exploring the other moves thoroughly gives better comparison between moves to find the optimal one. This is also easier because the small number of moves (4 directions).
    - Batch generation. Explore multiple lines simultaneously to allow the NN to generate moves in batches. This is presumably more efficient because of tensorflow/keras efficiency with batches (being treated as additional dimensions in an array).
